{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-preparation",
   "metadata": {},
   "source": [
    "![CC](https://i.creativecommons.org/l/by/4.0/88x31.png)\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "# Predicting the stability regime of rising bubbles\n",
    "\n",
    "**Note: this exercise still needs to be updated for the winter term 2022/2023.**\n",
    "\n",
    "In this exercise, we refine the classification model built in lecture 4. The model predicts the stability regime of rising bubbles based on the Galilei and Eötvös number. Picking up from the final state of the lecture, we extract and add new data, split the data into training and validation sets, and investigate how the decision boundaries change as we keep optimizing the model's parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-responsibility",
   "metadata": {},
   "source": [
    "## Extracting additional data (optional)\n",
    "\n",
    "This section explains how to extract additional data from another related article. The [lecture repository](https://github.com/AndreWeiner/ml-cfd-lecture) also provides a download link to the full dataset.\n",
    "\n",
    "### Installing Engauge Digitizer\n",
    "\n",
    "For this step, you need to download and install [Engauge Digitizer](http://markummitchell.github.io/engauge-digitizer/), or you use an alternative software of your choice with similar capabilities. The easiest way to install Engauge Digitizer on Ubuntu is via Snapcraft:\n",
    "\n",
    "```\n",
    "sudo snap install engauge-digitizer\n",
    "```\n",
    "\n",
    "### Extracting the data\n",
    "\n",
    "The *datasets/path_shape_regimes/* folder contains a screenshot of the experimental data recorded and published in [Shapes and paths of an air bubble rising in quiescent liquids](https://aip.scitation.org/doi/10.1063/1.5006726) by D. M. Sharaf et al. (figure 4). [This video](https://www.youtube.com/watch?v=5ChKRaBs0ys) demonstrates how to extract data points for a single regime from the screenshot. These steps have to be repeated for all four regime. Alternatively, the *datasets/path_shape_regimes/* folder already contains the extracted data for all four regimes. The new files follow the naming convection *exp_regime_[I,II,III,IV].csv*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec3352",
   "metadata": {},
   "source": [
    "## Loading, processing and visualizing the data\n",
    "\n",
    "First, load the new experimental in addition to the numerical data used in the lecture. The lecture notebook shows how to fetch the data with the Pandas library. When creating the *regime* column, merge regimes *IV* and *V* of the numerical data (set the value for both regimes to *IV*). Create also ordinal categories for each regime as demonstrated in the lecture. To verify that the data were loaded correctly, sample a few rows or use the `DataFrame.describe()` method.\n",
    "\n",
    "Since the investigated Galilei and Eötvös numbers are not very homogeneously distributed, we work with the common logarithm of both features. An additional normalization is not necessary. To see the effect of the logarithmic scaling, plot the original and the scaled regime data as scatter-plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d909ec6",
   "metadata": {},
   "source": [
    "## Training a neural network-based classification model\n",
    "\n",
    "### Training and validation data\n",
    "\n",
    "Since we have much more data now, we can split the data into training and validation sets. The training data are used to optimize the model's free parameters, and the validation data help to monitor the model's generalization. To split the data as done in lecture 3,\n",
    "\n",
    "- create feature and label tensors with all data points,\n",
    "- randomly select roughly 80% of the data for training, and\n",
    "- use the remaining data for validation.\n",
    "\n",
    "After this split, there should be six different PyTorch tensors: all features, training features, validation features, all labels, training labels, validation labels.\n",
    "\n",
    "### Optimizing the model parameters\n",
    "\n",
    "To create and train a new classification model, execute the following steps:\n",
    "\n",
    "- implement a neural network for classification in PyTorch\n",
    "- write an optimization loop employing the ADAM optimizer and the categorical cross entropy loss function\n",
    "- save the model's state after every 500 training epochs (refer to lecture 3 to recall how to save the state of a model); train the model for at least 3000 epochs with a learning rate of 0.002\n",
    "- monitor training and validation loss\n",
    "- plot the resulting decision boundaries for the saved model states\n",
    "- simultaneously observe the validation loss and the corresponding decision boundaries; can you detect over-fitting?\n",
    "\n",
    "**Congratulations! This completes the fourth exercise session.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b2b48",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
